
import os
import fitz  # PyMuPDF, PDF í…ìŠ¤íŠ¸ ì¶”ì¶œìš©
import streamlit as st  # Streamlitì„ ì‚¬ìš©í•˜ì—¬ ì›¹ ì¸í„°í˜ì´ìŠ¤ ìƒì„±
import time  # íƒ€ì´í•‘ íš¨ê³¼ë¥¼ ìœ„í•œ ë”œë ˆì´ ì„¤ì •

# LangChain ë° OpenAI API ê´€ë ¨ import
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langchain_core.chat_history import InMemoryChatMessageHistory, AIMessage, HumanMessage
from langchain_text_splitters import CharacterTextSplitter
from langchain.schema import Document
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.messages import HumanMessage, SystemMessage
from langchain.chains import RetrievalQA
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from langchain_community.cache import InMemoryCache  # LangChain ë©”ëª¨ë¦¬ ìºì‹œ ì¶”ê°€

os.environ['OPENAI_API_KEY'] = 'API_Key'
os.environ['LANGCHAIN_TRACING_V2'] = 'true'
os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'
os.environ["LANGCHAIN_API_KEY"] = 'API_Key'
os.environ["LANGCHAIN_PROJECT"] = 'aiproject1'

# PDF íŒŒì¼ì˜ ê° í˜ì´ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
def extract_text_by_pages(pdf_path: str):
    pdf_document = fitz.open(pdf_path)
    pages_text = []
    
    for page_number in range(pdf_document.page_count):
        page = pdf_document.load_page(page_number)
        pages_text.append(page.get_text("text"))
    
    pdf_document.close()
    return pages_text

# LangChain ëª¨ë¸ ì„¤ì •
llm = ChatOpenAI(model="gpt-4o-mini")

# Streamlitì—ì„œ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ìƒì„±
st.title("ìš©ì¸ì‹œ ìŠ¤ë§ˆíŠ¸íŒœ ì±—ë´‡ğŸŒ±")
st.write("ìš©ì¸ì‹œ ìŠ¤ë§ˆíŠ¸íŒœ ì°½ì—…ì¸ì„ ìœ„í•œ ê°€ì´ë“œ ì±—ë´‡ì…ë‹ˆë‹¤.ğŸ§‘ğŸ»â€ğŸŒ¾ ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”!")

# PDF ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
yongin_pdfs = ["news.pdf", "ìš©ì¸ë³‘í•´ì¶©.pdf", "ìš©ì¸ì§€ì›.pdf"]
smartfarm_pdfs = ["smartfarm_guide_1_OCR.pdf", "smartfarm_guide_2_OCR.pdf"]

# PDF í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ì´ˆê¸°í™” (ìºì‹œ ì ìš©)
pdfs_text_by_page = {pdf_path: extract_text_by_pages(pdf_path) for pdf_path in (yongin_pdfs + smartfarm_pdfs)}
if "conversation_history" not in st.session_state:
    st.session_state["conversation_history"] = []

# ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶œë ¥
for chat in st.session_state["conversation_history"]:
    role, content = chat.split(":", 1)
    if role == "User":
        st.chat_message("user").write(content.strip())
    elif role == "AI":
        st.chat_message("assistant").write(content.strip())

# ì§ˆë¬¸ ì…ë ¥ ë° ëŒ€í™” í‘œì‹œ
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:"):
    # ì‚¬ìš©ì ì…ë ¥ì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€í•˜ê³  í™”ë©´ì— í‘œì‹œ
    st.session_state["conversation_history"].append(f"User: {prompt}")
    with st.chat_message("user"):
        st.write(prompt)
    
    # 'ìš©ì¸' í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì§ˆë¬¸ì¸ì§€ í™•ì¸í•˜ì—¬ íƒìƒ‰í•  PDF íŒŒì¼ ì„¤ì •
    selected_pdfs = yongin_pdfs if "ìš©ì¸" in prompt else smartfarm_pdfs

    # ìœ ì‚¬ë„ ê¸°ë°˜ í˜ì´ì§€ ì„ íƒ
    max_similarity = 0
    best_page = None
    best_pdf_path = None

    # ì„ íƒí•œ PDF íŒŒì¼ì—ì„œë§Œ ìœ ì‚¬ë„ ê³„ì‚°
    for pdf_path in selected_pdfs:
        pages_text = pdfs_text_by_page[pdf_path]
        vectorizer = TfidfVectorizer().fit_transform([prompt] + pages_text)
        vectors = vectorizer.toarray()
        
        # queryì™€ í˜ì´ì§€ í…ìŠ¤íŠ¸ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        cosine_similarities = cosine_similarity(vectors[0:1], vectors[1:]).flatten()
        best_index = cosine_similarities.argmax()
        similarity = cosine_similarities[best_index]

        if similarity > max_similarity:
            max_similarity = similarity
            best_page = pages_text[best_index]
            best_pdf_path = pdf_path

    if best_page:
        # ì—­í•  ì§€ì¹¨ê³¼ íˆìŠ¤í† ë¦¬ë¥¼ í¬í•¨í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„±
        role_prompt = (
            "You are a specialized chatbot in smart farming and startup support for Yongin City. "
            "Answer questions based on provided materials, focusing on smart farm entrepreneurship. "
        )
        conversation_text = role_prompt + "\n".join(st.session_state["conversation_history"]) + f"\n\nMaterial:\n{best_page}"
        
        message = HumanMessage(content=conversation_text)
        response = llm.invoke([message])
        
        # AI ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        st.session_state["conversation_history"].append(f"AI: {response.content}")

        # í•œ ê¸€ìì”© íƒ€ì´í•‘ íš¨ê³¼ë¡œ AI ì‘ë‹µ ì¶œë ¥
        with st.chat_message("assistant"):
            typing_text = ""
            placeholder = st.empty()
            for char in response.content:
                typing_text += char
                placeholder.write(typing_text)
                time.sleep(0.05)  # íƒ€ì´í•‘ ì†ë„ ì¡°ì •
    else:
        st.session_state["conversation_history"].append("AI: ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        with st.chat_message("assistant"):
            st.write("ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
